{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предобработка текстов на русском языке. Извлечение ключевых слов и словосочетаний\n",
    "\n",
    "## Предобработка текстов на русском языке\n",
    "Для начала рассматриваем некоторое количество новостных сообщений, опубликованных в январе-феврале 2016 года, которые находятся в файле 'texts.json'. Мы считаем, что принципиальных различий между текстами нет, поэтому склеиваем их в один большой текст. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N of texts 221\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import json\n",
    "\n",
    "infile = '../data/texts.json'\n",
    "\n",
    "\n",
    "with open(infile) as data_file:    \n",
    "    data = json.load(data_file)\n",
    "collection = []\n",
    "for i in data['data']:\n",
    "    collection.append(i['text'])\n",
    "print 'N of texts', len(collection)\n",
    "merged_text = ' '.join(collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем самый простой токенизатор из NLTK, который разбивает тексты на токены по пробелам. Удаляем символы пунктуаци, цифры и несколько разных видов тире. Приводим текст к нижнему регистру – на этом стандартная и минимальная обработка текста заканчивается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "как\n",
      "вам\n",
      "удалось\n",
      "дать\n",
      "настолько\n",
      "точный\n",
      "прогноз\n",
      "у\n",
      "меня\n",
      "же\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from string import punctuation\n",
    "exclude = set(punctuation + '0123456789'+u'–—'+u'«»')\n",
    "merged_text = ''.join(ch for ch in merged_text if ch not in exclude)\n",
    "tokens = WhitespaceTokenizer().tokenize(merged_text.lower())\n",
    "for i in tokens[:10]: print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "print punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токен – словоупотребление (слово + его место в тексте), тип – словоформа. Чтобы посчитать количество типов в тексте используем частотные словари NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N of tokens:  148112\n",
      "N of types: 28570\n",
      "<FreqDist with 28570 samples and 148112 outcomes>\n"
     ]
    }
   ],
   "source": [
    "print 'N of tokens: ', len(tokens)\n",
    "types = nltk.FreqDist(tokens)\n",
    "print 'N of types:', len(types)\n",
    "print types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "в 6100\n",
      "и 3732\n",
      "на 3342\n",
      "не 2026\n",
      "что 1686\n",
      "по 1676\n",
      "с 1505\n",
      "за 963\n",
      "это 781\n",
      "года 777\n",
      "к 743\n",
      "а 729\n",
      "для 707\n",
      "как 625\n",
      "от 598\n",
      "до 593\n",
      "но 585\n",
      "о 545\n",
      "из 541\n",
      "году 531\n"
     ]
    }
   ],
   "source": [
    "for i in types.most_common(20):\n",
    "     print i[0], i[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим кривую Ципфа для текста и убедимся, что она выглядит правильно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEZCAYAAABWwhjiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wd2dGOG9yPJLgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108779c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fr = types.values()\n",
    "fr.sort(reverse=True)\n",
    "plt.plot(fr[:100])\n",
    "plt.ylabel('Type frequency')\n",
    "plt.xlabel('Type rank')\n",
    "plt.title(\"Zipf's law\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматризируем каждое слово с помощью PyMorphy2 и создаем частотный словарь лемм. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N of lemmata: 14789\n",
      "в 6188\n",
      "и 3726\n",
      "на 3342\n",
      "не 2026\n",
      "год 1740\n",
      "что 1723\n",
      "по 1675\n",
      "с 1645\n",
      "это 1372\n",
      "быть 1359\n",
      "за 962\n",
      "рубль 929\n",
      "который 795\n",
      "к 750\n",
      "а 726\n",
      "тот 715\n",
      "для 706\n",
      "о 703\n",
      "он 683\n",
      "цена 635\n"
     ]
    }
   ],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "lemmata = nltk.FreqDist()\n",
    "for t in types:\n",
    "    try:\n",
    "        l = morph.parse(t)[0].normal_form\n",
    "        if l in lemmata:\n",
    "            lemmata[l] += types[t]\n",
    "        else:\n",
    "            lemmata[l] = types[t]\n",
    "    except IndexError:\n",
    "        if t in lemmata:\n",
    "            lemmata[t] += types[t]\n",
    "        else:\n",
    "            lemmata[t] = types[t]\n",
    "print 'N of lemmata:', len(lemmata)\n",
    "for i in lemmata.most_common(20):\n",
    "    print i[0], i[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но разве все слова нам нужны? Не нужны нам стоп-слова: предлоги, местоимения, союзы и кое-что еще. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "и в во не что он на я с со как а то все она так его но да ты к у же вы за бы по только ее мне было вот от меня еще нет о из ему теперь когда даже ну вдруг ли если уже или ни быть был него до вас нибудь опять уж вам ведь там потом себя ничего ей может они тут где есть надо ней для мы тебя их чем была сам чтоб без будто чего раз тоже себе под будет ж тогда кто этот того потому этого какой совсем ним здесь этом один почти мой тем чтобы нее сейчас были куда зачем всех никогда можно при наконец два об другой хоть после над больше тот через эти нас про всего них какая много разве три эту моя впрочем хорошо свою этой перед иногда лучше чуть том нельзя такой им более всегда конечно всю между\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "for i in stopwords.words('russian'):\n",
    "    print i,\n",
    "mystopwords = stopwords.words('russian')+[u'это', u'иза', u'свой',u'млрд', u'млн',u'млна',u'тыс',u'трлн']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем список лемм без стоп слов и снова обновляем частотный словарь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "год 1742\n",
      "который 766\n",
      "рубль 758\n",
      "цена 636\n",
      "россия 520\n",
      "весь 500\n",
      "компания 463\n",
      "нефть 448\n",
      "рынок 442\n",
      "российский 426\n",
      "страна 425\n",
      "рост 325\n",
      "экономика 323\n",
      "говорить 307\n",
      "банка 278\n",
      "ещё 276\n",
      "также 267\n",
      "уровень 254\n",
      "данный 250\n",
      "мочь 247\n"
     ]
    }
   ],
   "source": [
    "lemmata_no_sw = nltk.FreqDist()\n",
    "for l in lemmata:\n",
    "    if not l in mystopwords:\n",
    "        lemmata_no_sw[l] = lemmata[l]\n",
    "for i in lemmata_no_sw.most_common(20):\n",
    "    print i[0], i[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь посмотрим только на существительные и подумаем о них как о *ключевых словах*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N of nouns: 6365\n",
      "год 1742\n",
      "рубль 758\n",
      "цена 636\n",
      "россия 520\n",
      "компания 463\n",
      "нефть 448\n",
      "рынок 442\n",
      "страна 425\n",
      "рост 325\n",
      "экономика 323\n",
      "банка 278\n",
      "уровень 254\n",
      "доллар 242\n",
      "млна 224\n",
      "правительство 222\n",
      "слово 221\n",
      "бюджет 218\n",
      "курс 218\n",
      "цб 218\n",
      "эксперт 215\n"
     ]
    }
   ],
   "source": [
    "nouns = nltk.FreqDist()\n",
    "for t in types:\n",
    "    if not t in mystopwords:\n",
    "        try:\n",
    "            gram_info = morph.parse(t)[0]\n",
    "            if 'NOUN' in gram_info.tag:\n",
    "                l = gram_info.normal_form\n",
    "                if l in nouns:\n",
    "                    nouns[l] += types[t]\n",
    "                else:\n",
    "                    nouns[l] = types[t]\n",
    "        except IndexError:\n",
    "            pass\n",
    "print 'N of nouns:', len(nouns)\n",
    "for i in nouns.most_common(20):\n",
    "    print i[0], i[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Извлечение ключевых словосочетаний по шаблону\n",
    "\n",
    "Допустим, что ключевым может быть словосочетание, которое удовлетворяет хорошему грамматическому шаблону, например, СУЩ + СУЩ, ПРИЛ + СУЩ. Попробуем извлечь все такие пары слов из текста. Функция match() принимает на вход n-граму – последовательность из n слов и проверяет ее на соответствие каждому шаблону. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "patterns = ['ADJF+NOUN','PRTS+NOUN','NOUN+NOUN']\n",
    "    \n",
    "def match(ngram, patterns = patterns):\n",
    "    index = []\n",
    "    for word in ngram:\n",
    "        if word in mystopwords:\n",
    "            return None\n",
    "        buf = [(p.normal_form, p.tag.POS) for p in morph.parse(word)]\n",
    "        index.append((word,buf)) \n",
    "    pos_tagging = product(*[ind[1] for ind in index])     \n",
    "    possible_patterns = map(lambda pos_tag: zip(*pos_tag), pos_tagging) \n",
    "    possible_patterns = map(lambda pattern: [pattern[0], map(lambda grammeme: grammeme, pattern[1])], possible_patterns)\n",
    "    possible_patterns = map(lambda pattern: (pattern[0], '+'.join(pattern[1])), possible_patterns)\n",
    "    for pattern in possible_patterns:\n",
    "       # print pattern\n",
    "        if pattern[1] in patterns:\n",
    "            return pattern\n",
    "\n",
    "    return None\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применяем функцию к тексту. Сразу виден существенный недостаток этой функции – словосочетания несогласованы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "прошлое год 141\n",
      "декабрь год 64\n",
      "саудовский аравия 60\n",
      "курс рубль 58\n",
      "январь год 53\n",
      "рост цена 47\n",
      "конец год 46\n",
      "нефтяной цена 46\n",
      "низкий цена 44\n",
      "первый очередь 44\n"
     ]
    }
   ],
   "source": [
    "pattern_coll2  = nltk.FreqDist() \n",
    "count = 0\n",
    "coll2 = nltk.FreqDist(nltk.bigrams(tokens))\n",
    "for c2 in coll2:\n",
    "    try:\n",
    "        p = match(c2)\n",
    "        if p != None:\n",
    "            collocation = ' '.join(p[0])\n",
    "            if collocation in pattern_coll2:\n",
    "                pattern_coll2[collocation] += coll2[c2]\n",
    "            else:\n",
    "                pattern_coll2[collocation] = coll2[c2]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for c2 in pattern_coll2.most_common(10):\n",
    "    print c2[0], c2[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Совсем несогласованы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "точный прогноз ADJF+NOUN\n",
      "весёлый музыка ADJF+NOUN\n"
     ]
    }
   ],
   "source": [
    "m = match([u'точный', u'прогноз'])\n",
    "print m[0][0], m[0][1], m[1]\n",
    "\n",
    "m = match([u'веселая', u'музыка'])\n",
    "print m[0][0], m[0][1], m[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Извлечение ключевых словосочетаний по статистическим мерам связности \n",
    "\n",
    "Используем реализацию из NLTK:\n",
    "* генерируем список биграм\n",
    "* удаляем биграмы, которые встречаются реже 3 раз\n",
    "* находим 20 биграм с максимальным значением статистического критерия\n",
    "\n",
    "Используем $t–score$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "в году\n",
      "на нефть\n",
      "при этом\n",
      "в том\n",
      "за баррель\n",
      "в россии\n",
      "цен на\n",
      "том что\n",
      "цены на\n",
      "то есть\n",
      "а также\n",
      "долл за\n",
      "том числе\n",
      "по итогам\n",
      "млрд рублей\n",
      "за счет\n",
      "по данным\n",
      "в этом\n",
      "прошлого года\n",
      "может быть\n"
     ]
    }
   ],
   "source": [
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_words(tokens)\n",
    "finder.apply_freq_filter(3)\n",
    "tscore_ranking = finder.nbest(bigram_measures.student_t, 20)\n",
    "for i in tscore_ranking: print ' '.join(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим стоп-слова и повторим все шаги заново. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "прошлого года\n",
      "прошлом году\n",
      "первую очередь\n",
      "января года\n",
      "итогам года\n",
      "таким образом\n",
      "нефтяных цен\n",
      "саудовской аравии\n",
      "см «нг»\n",
      "декабря года\n",
      "декабре года\n",
      "курс рубля\n",
      "речь идет\n",
      "курса рубля\n",
      "точки зрения\n",
      "владимир путин\n",
      "саудовская аравия\n",
      "ближайшее время\n",
      "экономического роста\n",
      "низких цен\n"
     ]
    }
   ],
   "source": [
    "finder.apply_word_filter(lambda w: w in mystopwords)\n",
    "tscore_ranking = finder.nbest(bigram_measures.student_t, 20)\n",
    "for i in tscore_ranking: print ' '.join(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем  $PMI$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liqui moly\n",
      "shanghai composite\n",
      "«эксон нл»\n",
      "исламского банкинга\n",
      "клаус шваб\n",
      "нижний новгород\n",
      "ньюйоркская конвенция\n",
      "парниковых газов\n",
      "температура кристаллизации\n",
      "товарных рынков»\n",
      "wall street\n",
      "«взлетная полоса»\n",
      "«экологический менеджмент»\n",
      "хасан рухани\n",
      "эммануэль ибе\n",
      "electric power\n",
      "iron ore\n",
      "new york\n",
      "«сахалин энерджи»\n",
      "«фридом финанс»\n"
     ]
    }
   ],
   "source": [
    "pmi_ranking =  finder.nbest(bigram_measures.pmi, 20)\n",
    "for i in pmi_ranking: print ' '.join(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем $\\chi^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "electric power\n",
      "forex club\n",
      "goldman sachs\n",
      "iron ore\n",
      "liqui moly\n",
      "mfx broker\n",
      "new york\n",
      "qb finance\n",
      "shanghai composite\n",
      "«деловой фарватер»\n",
      "«сахалин энерджи»\n",
      "«фридом финанс»\n",
      "«эксон нл»\n",
      "«южного потока»\n",
      "генеральная прокуратура\n",
      "исламского банкинга\n",
      "квадратного метра\n",
      "клаус шваб\n",
      "кристин лагард\n",
      "ксения юдаева\n"
     ]
    }
   ],
   "source": [
    "chi2_ranking =  finder.nbest(bigram_measures.chi_sq, 20)\n",
    "for i in chi2_ranking: print ' '.join(i).encode('utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем $LogLikelihood Ratio$, $LLR$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "прошлого года\n",
      "первую очередь\n",
      "прошлом году\n",
      "саудовской аравии\n",
      "таким образом\n",
      "см «нг»\n",
      "саудовская аравия\n",
      "точки зрения\n",
      "речь идет\n",
      "риа новости\n",
      "нефтяных цен\n",
      "сих пор\n",
      "владимир путин\n",
      "января года\n",
      "итогам года\n",
      "«черного золота»\n",
      "ближайшее время\n",
      "любом случае\n",
      "алексей улюкаев\n",
      "нефтяных котировок\n"
     ]
    }
   ],
   "source": [
    "llr_ranking = finder.nbest(bigram_measures.likelihood_ratio, 20)\n",
    "for i in llr_ranking: print ' '.join(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнение полученных ранжировок можно выаолнить с помощью рангового коэффициента корреляции Спирмена.\n",
    "\n",
    "Определение (http://www.machinelearning.ru/)\n",
    "\n",
    "Заданы две выборки $x = (x_1,\\ldots,x_n)$, $y = (y_1,\\ldots,y_n)$.\n",
    "\n",
    "Вычисление корреляции Спирмена:\n",
    "\n",
    "Коэффициент корреляции Спирмена вычисляется по формуле:\n",
    "$\\rho=1-\\frac{6}{n(n-1)(n+1)}\\sum_{i=1}^n(R_i-S_i)^2$, где $R_i$ - ранг наблюдения $x_i$ в ряду $x$, $S_i$ - ранг наблюдения $y_i$ в ряду $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from nltk.metrics.spearman import *\n",
    "pmi_ranks =  ranks_from_sequence(pmi_ranking)\n",
    "tscore_ranks = ranks_from_sequence(tscore_ranking)\n",
    "print spearman_correlation(pmi_ranks, tscore_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0791208791209\n"
     ]
    }
   ],
   "source": [
    "llr_ranks =  ranks_from_sequence(llr_ranking)\n",
    "tscore_ranks = ranks_from_sequence(tscore_ranking)\n",
    "print spearman_correlation(llr_ranks, tscore_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "долл баррель\n",
      "прошлого года\n",
      "нефть баррель\n",
      "прошлом году\n",
      "итогам года\n",
      "рублей рублей\n",
      "цен нефть\n",
      "долл долл\n",
      "руб руб\n",
      "цены нефть\n",
      "году году\n",
      "курс рубля\n",
      "первую очередь\n",
      "января года\n",
      "нефтяных цен\n",
      "нефть долл\n",
      "баррель долл\n",
      "рубля рубля\n",
      "таким образом\n",
      "конце года\n"
     ]
    }
   ],
   "source": [
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_words(tokens, window_size = 20)\n",
    "finder.apply_freq_filter(2)\n",
    "\n",
    "finder.apply_word_filter(lambda w: len(w) < 3 or w.lower() in mystopwords)\n",
    "\n",
    "tscore_ranking = finder.nbest(bigram_measures.student_t, 20)\n",
    "\n",
    "for i in tscore_ranking: print ' '.join(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Стемминг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "оптимизац\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import RussianStemmer\n",
    "stemmer = RussianStemmer()\n",
    "print stemmer.stem(u'оптимизация')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Частотный словарь стемов (псевдооснов):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "год 1602\n",
      "котор 795\n",
      "рубл 759\n",
      "цен 646\n",
      "росс 522\n",
      "банк 478\n",
      "компан 464\n",
      "нефт 448\n",
      "стран 433\n",
      "российск 426\n",
      "говор 404\n",
      "так 353\n",
      "рост 325\n",
      "экономик 324\n",
      "рынк 323\n",
      "нов 295\n",
      "такж 267\n",
      "дан 261\n",
      "сам 260\n",
      "сво 247\n"
     ]
    }
   ],
   "source": [
    "stems = nltk.FreqDist()\n",
    "for t in types:\n",
    "    if not t in mystopwords:\n",
    "        stem = stemmer.stem(t)\n",
    "        if stem in stems:\n",
    "            stems[stem] += types[t]\n",
    "        else:\n",
    "            stems[stem] = types[t]\n",
    "for i in stems.most_common(20):\n",
    "    print i[0], i[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Задание 1\n",
    "\n",
    "Найдите ключевые слова и словосочетания для произвольного текста с использованием грамматических шаблонов и хотя бы одной статистической меры связности. Прокомментируйте полученные результаты.\n",
    "\n",
    "# Задание 2 \n",
    "\n",
    "Напишите функцию concord(), которая принимает на вход:\n",
    "* несогласованное словосочетание\n",
    "* шаблон словосочетания\n",
    "и возвращает согласованное словосочетание.\n",
    "\n",
    "# Задание 3 \n",
    "\n",
    "Реализуйте TextRank и сравните результаты его применения с результами задания 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Литература\n",
    "\n",
    "* Manning & Shuetze: Ch. 5 – Collocations\n",
    "\n",
    "* NLTK Book: Collocations HOWTO http://www.nltk.org/howto/collocations.html\n",
    "\n",
    "* Е. В. Ягунова, Л. М. Пивоварова,  \"От конструкций к коллокациям\" – http://webground.su/data/lit/pivovarova_yagunova/Ot_kollokatsiy_k_konstruktsiyam.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 (SageMath)",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "name": "Russian_preprocessing_kp_extraction.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
